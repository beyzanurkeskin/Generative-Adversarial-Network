{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6daf15b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8894c",
   "metadata": {},
   "source": [
    " ## BAF Veri Setinden GAN ile Yapa Veri Üretimi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9311ceb",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03a3ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Beyza\\anaconda3\\anacondaa3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\Beyza\\anaconda3\\anacondaa3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9055c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base.csv')  \n",
    "data = pd.read_csv('base.csv') \n",
    "\n",
    "categorical_columns = ['income', 'customer_age', 'payment_type', 'employment_status', 'housing_status', 'source', 'device_os', 'device_distinct_emails_8w', 'device_fraud_count', 'month']\n",
    "\n",
    "# OneHotEncoder ile kategorik sütunları dönüştür\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "encoded_df = pd.DataFrame(encoder.fit_transform(df[categorical_columns]))\n",
    "\n",
    "# Encode edilmiş sütunları orijinal veri çerçevesine ekle\n",
    "encoded_df.columns = encoder.get_feature_names_out(categorical_columns)\n",
    "\n",
    "# Kategorik sütunları orijinal veri çerçevesinden çıkar\n",
    "df = df.drop(columns=categorical_columns)\n",
    "\n",
    "# Yeni encode edilmiş sütunları ekle\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "# 'fraud_bool' sütununu sakla\n",
    "fraud_bool = df['fraud_bool']\n",
    "\n",
    "# Diğer sütunları ölçekle\n",
    "columns_to_scale = df.columns.difference(['fraud_bool'])\n",
    "scaler = StandardScaler()\n",
    "scaled_df = df.copy()\n",
    "scaled_df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "# 'fraud_bool' sütununu tekrar ekle\n",
    "scaled_df['fraud_bool'] = fraud_bool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c7cbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Beyza\\anaconda3\\anacondaa3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 93>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU eğitim süresi: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgpu_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saniye\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m     cpu_time \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU eğitim süresi: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcpu_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saniye\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     78\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, latent_dim)\u001b[38;5;241m.\u001b[39mto(device)  \n\u001b[0;32m     79\u001b[0m fake_data \u001b[38;5;241m=\u001b[39m generator(z) \n\u001b[1;32m---> 80\u001b[0m \u001b[43moptimizer_g\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m outputs \u001b[38;5;241m=\u001b[39m discriminator(fake_data)\n\u001b[0;32m     82\u001b[0m g_loss \u001b[38;5;241m=\u001b[39m criterion(outputs, real_labels)\n",
      "File \u001b[1;32m~\\anaconda3\\anacondaa3\\lib\\site-packages\\torch\\_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\anacondaa3\\lib\\site-packages\\torch\\_dynamo\\decorators.py:47\u001b[0m, in \u001b[0;36mdisable\u001b[1;34m(fn, recursive)\u001b[0m\n\u001b[0;32m     45\u001b[0m         fn \u001b[38;5;241m=\u001b[39m innermost_fn(fn)\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[1;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDisableContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DisableContext()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\anacondaa3\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:290\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 290\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetsourcefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\anacondaa3\\lib\\inspect.py:706\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(filename\u001b[38;5;241m.\u001b[39mendswith(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m\n\u001b[0;32m    704\u001b[0m              importlib\u001b[38;5;241m.\u001b[39mmachinery\u001b[38;5;241m.\u001b[39mEXTENSION_SUFFIXES):\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n\u001b[0;32m    708\u001b[0m \u001b[38;5;66;03m# only return a non-existent filename if the module has a PEP 302 loader\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\anacondaa3\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "num_epochs = 20  \n",
    "batch_size = 64\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "generator = Generator(input_dim=latent_dim, output_dim=scaled_df.shape[1]).to(device)\n",
    "discriminator = Discriminator(input_dim=scaled_df.shape[1]).to(device)\n",
    "\n",
    "# Adjusted learning rates\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.0003, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.00005, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "data_tensor = torch.tensor(scaled_df.values, dtype=torch.float32).to(device)\n",
    "train_loader = DataLoader(TensorDataset(data_tensor), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def train_model():\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        for real_data in train_loader:\n",
    "            real_data = real_data[0]\n",
    "\n",
    "            batch_size = real_data.size(0)\n",
    "            real_labels = torch.full((batch_size, 1), 0.9, device=device)  # Gerçek etiketler için 0.9\n",
    "            fake_labels = torch.full((batch_size, 1), 0.1, device=device)  # Sahte etiketler için 0.1\n",
    "\n",
    "\n",
    "            # Discriminator training\n",
    "            optimizer_d.zero_grad()\n",
    "            outputs = discriminator(real_data)\n",
    "            d_loss_real = criterion(outputs, real_labels)\n",
    "            d_loss_real.backward()\n",
    "\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_data = generator(z)\n",
    "            outputs = discriminator(fake_data.detach())\n",
    "            d_loss_fake = criterion(outputs, fake_labels)\n",
    "            d_loss_fake.backward()\n",
    "            optimizer_d.step()\n",
    "\n",
    "\n",
    "            for _ in range(2):  \n",
    "                z = torch.randn(batch_size, latent_dim).to(device)  \n",
    "                fake_data = generator(z) \n",
    "                optimizer_g.zero_grad()\n",
    "                outputs = discriminator(fake_data)\n",
    "                g_loss = criterion(outputs, real_labels)\n",
    "                g_loss.backward()  \n",
    "                optimizer_g.step()\n",
    "\n",
    "\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] | D Loss: {d_loss_real.item() + d_loss_fake.item()} | G Loss: {g_loss.item()}')\n",
    "\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    gpu_time = train_model()\n",
    "    print(f\"GPU eğitim süresi: {gpu_time:.2f} saniye\")\n",
    "else:\n",
    "    cpu_time = train_model()\n",
    "    print(f\"CPU eğitim süresi: {cpu_time:.2f} saniye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bef62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000000\n",
    "noise = torch.randn(num_samples, latent_dim)\n",
    "\n",
    "generated_data = generator(noise).detach().numpy()\n",
    "\n",
    "generated_df = pd.DataFrame(generated_data, columns=scaled_df.columns)\n",
    "\n",
    "generated_df[columns_to_scale] = scaler.inverse_transform(generated_df[columns_to_scale])\n",
    "\n",
    "categorical_output = pd.DataFrame(encoder.inverse_transform(generated_df[encoded_df.columns]))\n",
    "categorical_output.columns = categorical_columns\n",
    "\n",
    "generated_df = generated_df.drop(columns=encoded_df.columns)\n",
    "generated_df = pd.concat([generated_df, categorical_output], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae96c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ebbc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_df[\"fraud_bool\"] = generated_df[\"fraud_bool\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = generated_df.sort_values(by='fraud_bool', ascending=False).reset_index()\n",
    "\n",
    "df_sorted.loc[:9999, 'fraud_bool'] = 1  \n",
    "df_sorted.loc[10000:, 'fraud_bool'] = 0  \n",
    "\n",
    "generated_df['fraud_bool'] = df_sorted.sort_values(by='index').reset_index(drop=True)['fraud_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b484392",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "\n",
    "features = df.columns\n",
    "\n",
    "num_features = len(features)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns  \n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_columns, figsize=(20, num_rows * 5))\n",
    "fig.tight_layout(pad=5.0)  \n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    row = i // num_columns\n",
    "    col = i % num_columns\n",
    "    \n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    min_val = min(df[feature].min(), generated_df[feature].min())\n",
    "    max_val = max(df[feature].max(), generated_df[feature].max())\n",
    "    \n",
    "    ax.hist(df[feature], bins=30, alpha=0.5, label='Gerçek Veri', color='blue', range=(min_val, max_val))\n",
    "    ax.hist(generated_df[feature], bins=30, alpha=0.5, label='Yapay Veri', color='yellow', range=(min_val, max_val))\n",
    "    \n",
    "    ax.set_title(f'{feature} - Gerçek ve Yapay Veriler')\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Frekans')\n",
    "    ax.legend()\n",
    "\n",
    "for j in range(len(features), num_rows * num_columns):\n",
    "    fig.delaxes(axes[j // num_columns, j % num_columns])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20670af1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
