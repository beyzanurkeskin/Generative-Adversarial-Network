{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6daf15b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c8894c",
   "metadata": {},
   "source": [
    "![Görüntü Açıklaması](bafgan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9311ceb",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84309393",
   "metadata": {},
   "source": [
    " ## Gerekli Kütüphanelerin Eklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a3ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12bf09",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4905a484",
   "metadata": {},
   "source": [
    " ## Veri Seti İçin Ön İşlemler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9055c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('base.csv')  \n",
    "data = pd.read_csv('base.csv') \n",
    "\n",
    "categorical_columns = ['income', 'customer_age', 'payment_type', 'employment_status', 'housing_status', 'source', 'device_os', 'device_distinct_emails_8w', 'device_fraud_count', 'month']\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "encoded_df = pd.DataFrame(encoder.fit_transform(df[categorical_columns]))\n",
    "\n",
    "encoded_df.columns = encoder.get_feature_names_out(categorical_columns)\n",
    "\n",
    "df = df.drop(columns=categorical_columns)\n",
    "\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "\n",
    "fraud_bool = df['fraud_bool']\n",
    "\n",
    "binary_columns = [\"email_is_free\",\"phone_home_valid\",\"phone_mobile_valid\",\"has_other_cards\",\"foreign_request\",\"keep_alive_session\"]  # Binary sütunların isimleri\n",
    "columns_to_scale = df.columns.difference(['fraud_bool'] + binary_columns)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_df = df.copy()\n",
    "scaled_df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "scaled_df['fraud_bool'] = fraud_bool\n",
    "scaled_df[binary_columns] = df[binary_columns] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d4e3a5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3403e974",
   "metadata": {},
   "source": [
    " ## Modelin Kurulması ve Kaydedilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aef5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 1024\n",
    "num_epochs = 100\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c7cbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Beyza\\anaconda3\\anacondaa3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Epoch [1/100] | D Loss: 0.6900216937065125 | G Loss: 2.2028658390045166\n",
      "Epoch [2/100] | D Loss: 0.7642569541931152 | G Loss: 1.5859657526016235\n",
      "Epoch [3/100] | D Loss: 0.735119640827179 | G Loss: 2.0101470947265625\n",
      "Epoch [4/100] | D Loss: 0.6549120545387268 | G Loss: 2.095292568206787\n",
      "Epoch [5/100] | D Loss: 0.6535765826702118 | G Loss: 2.0708212852478027\n",
      "Epoch [6/100] | D Loss: 0.6511710286140442 | G Loss: 2.0806498527526855\n",
      "Epoch [7/100] | D Loss: 0.6508444547653198 | G Loss: 2.090548515319824\n",
      "Epoch [8/100] | D Loss: 0.6835614740848541 | G Loss: 2.0646584033966064\n",
      "Epoch [9/100] | D Loss: 0.6502811908721924 | G Loss: 2.0837135314941406\n",
      "Epoch [10/100] | D Loss: 0.6503421068191528 | G Loss: 2.095125913619995\n",
      "Epoch [11/100] | D Loss: 0.6502617597579956 | G Loss: 2.0862958431243896\n",
      "Epoch [12/100] | D Loss: 0.6506488025188446 | G Loss: 2.0837883949279785\n",
      "Epoch [13/100] | D Loss: 0.6502555906772614 | G Loss: 2.088930606842041\n",
      "Epoch [14/100] | D Loss: 0.6502152979373932 | G Loss: 2.0802981853485107\n",
      "Epoch [15/100] | D Loss: 0.650262326002121 | G Loss: 2.0808229446411133\n",
      "Epoch [16/100] | D Loss: 0.6502338945865631 | G Loss: 2.0850183963775635\n",
      "Epoch [17/100] | D Loss: 0.6503106951713562 | G Loss: 2.082615613937378\n",
      "Epoch [18/100] | D Loss: 0.6503862738609314 | G Loss: 2.1116693019866943\n",
      "Epoch [19/100] | D Loss: 0.6502037048339844 | G Loss: 2.080533981323242\n",
      "Epoch [20/100] | D Loss: 0.6515543162822723 | G Loss: 2.0945777893066406\n",
      "Epoch [21/100] | D Loss: 0.6504230201244354 | G Loss: 2.1234893798828125\n",
      "Epoch [22/100] | D Loss: 0.6501886248588562 | G Loss: 2.079622745513916\n",
      "Epoch [23/100] | D Loss: 0.6502222120761871 | G Loss: 2.09181809425354\n",
      "Epoch [24/100] | D Loss: 0.6502186954021454 | G Loss: 2.0950496196746826\n",
      "Epoch [25/100] | D Loss: 0.6514795124530792 | G Loss: 2.0558409690856934\n",
      "Epoch [26/100] | D Loss: 0.6504800915718079 | G Loss: 2.0972135066986084\n",
      "Epoch [27/100] | D Loss: 0.6503192186355591 | G Loss: 2.0870213508605957\n",
      "Epoch [28/100] | D Loss: 0.6515447199344635 | G Loss: 2.0840272903442383\n",
      "Epoch [29/100] | D Loss: 0.6501882374286652 | G Loss: 2.085850477218628\n",
      "Epoch [30/100] | D Loss: 0.6502585411071777 | G Loss: 2.093745470046997\n",
      "Epoch [31/100] | D Loss: 0.6502020061016083 | G Loss: 2.083960771560669\n",
      "Epoch [32/100] | D Loss: 0.6502366065979004 | G Loss: 2.0850167274475098\n",
      "Epoch [33/100] | D Loss: 0.6502278745174408 | G Loss: 2.073612928390503\n",
      "Epoch [34/100] | D Loss: 0.6757458448410034 | G Loss: 2.007572650909424\n",
      "Epoch [35/100] | D Loss: 0.6503672003746033 | G Loss: 2.092582941055298\n",
      "Epoch [36/100] | D Loss: 0.6734536588191986 | G Loss: 2.017411708831787\n",
      "Epoch [37/100] | D Loss: 0.6502171754837036 | G Loss: 2.080345630645752\n",
      "Epoch [38/100] | D Loss: 0.650236964225769 | G Loss: 2.0879015922546387\n",
      "Epoch [39/100] | D Loss: 0.6502172648906708 | G Loss: 2.074777841567993\n",
      "Epoch [40/100] | D Loss: 0.6501745283603668 | G Loss: 2.078267812728882\n",
      "Epoch [41/100] | D Loss: 0.6507292091846466 | G Loss: 2.0746707916259766\n",
      "Epoch [42/100] | D Loss: 0.650222659111023 | G Loss: 2.0779640674591064\n",
      "Epoch [43/100] | D Loss: 0.6502655446529388 | G Loss: 2.055577516555786\n",
      "Epoch [44/100] | D Loss: 0.6501726806163788 | G Loss: 2.080263137817383\n",
      "Epoch [45/100] | D Loss: 0.6501732468605042 | G Loss: 2.081728935241699\n",
      "Epoch [46/100] | D Loss: 0.650206446647644 | G Loss: 2.0873119831085205\n",
      "Epoch [47/100] | D Loss: 0.6502833962440491 | G Loss: 2.084442615509033\n",
      "Epoch [48/100] | D Loss: 0.6501978039741516 | G Loss: 2.0805015563964844\n",
      "Epoch [49/100] | D Loss: 0.6501806378364563 | G Loss: 2.0770509243011475\n",
      "Epoch [50/100] | D Loss: 0.6502206325531006 | G Loss: 2.0765089988708496\n",
      "Epoch [51/100] | D Loss: 0.6502965092658997 | G Loss: 2.0955824851989746\n",
      "Epoch [52/100] | D Loss: 0.6501877307891846 | G Loss: 2.0858020782470703\n",
      "Epoch [53/100] | D Loss: 0.6501717567443848 | G Loss: 2.081895351409912\n",
      "Epoch [54/100] | D Loss: 0.6501680016517639 | G Loss: 2.0823347568511963\n",
      "Epoch [55/100] | D Loss: 0.650173544883728 | G Loss: 2.0874524116516113\n",
      "Epoch [56/100] | D Loss: 0.6502016484737396 | G Loss: 2.0793821811676025\n",
      "Epoch [57/100] | D Loss: 0.6501818597316742 | G Loss: 2.0784008502960205\n",
      "Epoch [58/100] | D Loss: 0.6749350726604462 | G Loss: 2.02032470703125\n",
      "Epoch [59/100] | D Loss: 0.6501865386962891 | G Loss: 2.0786378383636475\n",
      "Epoch [60/100] | D Loss: 0.650178074836731 | G Loss: 2.087224006652832\n",
      "Epoch [61/100] | D Loss: 0.6501807272434235 | G Loss: 2.0821001529693604\n",
      "Epoch [62/100] | D Loss: 0.6501746475696564 | G Loss: 2.082773208618164\n",
      "Epoch [63/100] | D Loss: 0.6501775979995728 | G Loss: 2.0843751430511475\n",
      "Epoch [64/100] | D Loss: 0.6502147614955902 | G Loss: 2.0788230895996094\n",
      "Epoch [65/100] | D Loss: 0.6501778066158295 | G Loss: 2.082751512527466\n",
      "Epoch [66/100] | D Loss: 0.6501674950122833 | G Loss: 2.083070993423462\n",
      "Epoch [67/100] | D Loss: 0.65016770362854 | G Loss: 2.0825963020324707\n",
      "Epoch [68/100] | D Loss: 0.6501871645450592 | G Loss: 2.082698106765747\n",
      "Epoch [69/100] | D Loss: 0.6501722633838654 | G Loss: 2.081935405731201\n",
      "Epoch [70/100] | D Loss: 0.650194525718689 | G Loss: 2.0856516361236572\n",
      "Epoch [71/100] | D Loss: 0.650199294090271 | G Loss: 2.089169979095459\n",
      "Epoch [72/100] | D Loss: 0.6501730382442474 | G Loss: 2.0832388401031494\n",
      "Epoch [73/100] | D Loss: 0.6501741111278534 | G Loss: 2.084155321121216\n",
      "Epoch [74/100] | D Loss: 0.6501783728599548 | G Loss: 2.0825865268707275\n",
      "Epoch [75/100] | D Loss: 0.6550970673561096 | G Loss: 2.081735849380493\n",
      "Epoch [76/100] | D Loss: 0.6501722633838654 | G Loss: 2.08329439163208\n",
      "Epoch [77/100] | D Loss: 0.6501672267913818 | G Loss: 2.0827183723449707\n",
      "Epoch [78/100] | D Loss: 0.6501672863960266 | G Loss: 2.082937240600586\n",
      "Epoch [79/100] | D Loss: 0.6502275764942169 | G Loss: 2.083371877670288\n",
      "Epoch [80/100] | D Loss: 0.6501718461513519 | G Loss: 2.0807082653045654\n",
      "Epoch [81/100] | D Loss: 0.6501667201519012 | G Loss: 2.082873582839966\n",
      "Epoch [82/100] | D Loss: 0.6502840220928192 | G Loss: 2.081528425216675\n",
      "Epoch [83/100] | D Loss: 0.6501964330673218 | G Loss: 2.085571527481079\n",
      "Epoch [84/100] | D Loss: 0.6501737833023071 | G Loss: 2.087239980697632\n",
      "Epoch [85/100] | D Loss: 0.6501666605472565 | G Loss: 2.0826897621154785\n",
      "Epoch [86/100] | D Loss: 0.6501964032649994 | G Loss: 2.0826218128204346\n",
      "Epoch [87/100] | D Loss: 0.6501712799072266 | G Loss: 2.0830564498901367\n",
      "Epoch [88/100] | D Loss: 0.6501679718494415 | G Loss: 2.0820417404174805\n",
      "Epoch [89/100] | D Loss: 0.6502144038677216 | G Loss: 2.0860707759857178\n",
      "Epoch [90/100] | D Loss: 0.650170624256134 | G Loss: 2.083111524581909\n",
      "Epoch [91/100] | D Loss: 0.6501668095588684 | G Loss: 2.083111524581909\n",
      "Epoch [92/100] | D Loss: 0.6501669585704803 | G Loss: 2.0831336975097656\n",
      "Epoch [93/100] | D Loss: 0.6501669883728027 | G Loss: 2.08273983001709\n",
      "Epoch [94/100] | D Loss: 0.6502057909965515 | G Loss: 2.083475112915039\n",
      "Epoch [95/100] | D Loss: 0.650241494178772 | G Loss: 2.0733091831207275\n",
      "Epoch [96/100] | D Loss: 0.650177538394928 | G Loss: 2.0821051597595215\n",
      "Epoch [97/100] | D Loss: 0.6504731476306915 | G Loss: 2.0925252437591553\n",
      "Epoch [98/100] | D Loss: 0.6501674950122833 | G Loss: 2.082731246948242\n",
      "Epoch [99/100] | D Loss: 0.6501772701740265 | G Loss: 2.0805113315582275\n",
      "Epoch [100/100] | D Loss: 0.6501861810684204 | G Loss: 2.080723285675049\n",
      "CPU eğitim süresi: 73616.64 saniye\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "generator = Generator(input_dim=latent_dim, output_dim=scaled_df.shape[1]).to(device)\n",
    "discriminator = Discriminator(input_dim=scaled_df.shape[1]).to(device)\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.0003, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.00005, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "data_tensor = torch.tensor(scaled_df.values, dtype=torch.float32).to(device)\n",
    "train_loader = DataLoader(TensorDataset(data_tensor), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def train_model():\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        for real_data in train_loader:\n",
    "            real_data = real_data[0]\n",
    "\n",
    "            batch_size = real_data.size(0)\n",
    "            real_labels = torch.full((batch_size, 1), 0.9, device=device) \n",
    "            fake_labels = torch.full((batch_size, 1), 0.1, device=device) \n",
    "\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_data = generator(z)\n",
    "\n",
    "            for _ in range(2):  \n",
    "                optimizer_d.zero_grad()\n",
    "                outputs = discriminator(real_data)\n",
    "                d_loss_real = criterion(outputs, real_labels)\n",
    "                d_loss_real.backward()\n",
    "\n",
    "                outputs = discriminator(fake_data.detach())\n",
    "                d_loss_fake = criterion(outputs, fake_labels)\n",
    "                d_loss_fake.backward()\n",
    "                optimizer_d.step()\n",
    "\n",
    "            # Generator eğitimi\n",
    "            optimizer_g.zero_grad()\n",
    "            outputs = discriminator(fake_data)\n",
    "            g_loss = criterion(outputs, real_labels)\n",
    "            g_loss.backward()  \n",
    "            optimizer_g.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] | D Loss: {d_loss_real.item() + d_loss_fake.item()} | G Loss: {g_loss.item()}')\n",
    "\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    gpu_time = train_model()\n",
    "    print(f\"GPU eğitim süresi: {gpu_time:.2f} saniye\")\n",
    "else:\n",
    "    cpu_time = train_model()\n",
    "    print(f\"CPU eğitim süresi: {cpu_time:.2f} saniye\")\n",
    "\n",
    "with open('generator_model.pkl', 'wb') as f:\n",
    "    pickle.dump(generator.state_dict(), f)\n",
    "\n",
    "with open('discriminator_model.pkl', 'wb') as f:\n",
    "    pickle.dump(discriminator.state_dict(), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
